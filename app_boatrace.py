import os
# Force single thread to prevent Streamlit Cloud crashes (OpenMP)
os.environ['OMP_NUM_THREADS'] = '1'

import streamlit as st
import pandas as pd
import numpy as np
import lightgbm as lgb
import requests
from bs4 import BeautifulSoup
import datetime
import re
import time
import sys

# --- Configuration ---
st.set_page_config(page_title="BoatRace AI Predictor", layout="wide")

MODEL_PATH = 'lgb_ranker.txt'
DATA_DIR = 'app_data'
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}

# --- 1. Scraper Class ---
class BoatRaceScraper:
    @staticmethod
    def get_soup(url):
        max_retries = 3
        for attempt in range(max_retries):
            try:
                resp = requests.get(url, headers=HEADERS, timeout=15)
                resp.raise_for_status()
                resp.encoding = resp.apparent_encoding
                return BeautifulSoup(resp.text, 'html.parser')
            except Exception as e:
                if attempt == max_retries - 1:
                    st.error(f"Data Fetch Error: {e}")
                    return None
                time.sleep(1)
        return None

    @staticmethod
    def parse_float(text):
        try:
            return float(re.search(r'([\d\.]+)', text).group(1))
        except:
            return 0.0

    @staticmethod
    def get_race_data(date_str, venue_code, race_no):
        jcd = f"{int(venue_code):02d}"
        url_before = f"https://www.boatrace.jp/owpc/pc/race/beforeinfo?rno={race_no}&jcd={jcd}&hd={date_str}"
        url_list = f"https://www.boatrace.jp/owpc/pc/race/racelist?rno={race_no}&jcd={jcd}&hd={date_str}"
        
        soup_before = BoatRaceScraper.get_soup(url_before)
        soup_list = BoatRaceScraper.get_soup(url_list)
        
        if not soup_before or not soup_list:
            return None
            
        # Parse Wind & Weather
        weather = {'wind_direction': 0, 'wind_speed': 0.0, 'wave_height': 0.0}
        try:
            w = soup_before.select_one("div.weather1_body")
            if w:
                ws = w.select_one(".is-wind span.weather1_bodyUnitLabelData")
                if ws: weather['wind_speed'] = BoatRaceScraper.parse_float(ws.text)
                wh = w.select_one(".is-wave span.weather1_bodyUnitLabelData")
                if wh: weather['wave_height'] = BoatRaceScraper.parse_float(wh.text)
                wd = w.select_one(".is-windDirection p")
                if wd:
                    cls = wd.get('class', [])
                    d = next((c for c in cls if c.startswith('is-wind') and c != 'is-windDirection'), None)
                    if d: weather['wind_direction'] = int(re.sub(r'\D', '', d))
        except: pass

        # Parse Exhibition/ST
        boat_before = {}
        try:
            # Exhibition Time
            for i, tb in enumerate(soup_before.select("table.is-w748 tbody")):
                tds = tb.select("td")
                if len(tds) >= 5:
                    boat_before[i+1] = {'ex_time': BoatRaceScraper.parse_float(tds[4].text), 'st': 0.20}
            # ST
            for row in soup_before.select("table.is-w238 tbody tr"):
                bn_span = row.select_one("span.table1_boatImage1Number")
                if bn_span:
                    b = int(bn_span.text.strip())
                    st_span = row.select_one("span.table1_boatImage1Time")
                    val = 0.20
                    if st_span:
                        txt_raw = st_span.text.strip()
                        # Handle F/L
                        if 'L' in txt_raw: val = 1.0
                        elif 'F' in txt_raw:
                            try:
                                # F.01 -> -0.01
                                sub = txt_raw.replace('F', '')
                                val = -float(sub)
                            except: val = -0.05
                        else:
                            # .12 -> 0.12
                            val = BoatRaceScraper.parse_float(txt_raw)
                            
                    if b in boat_before: boat_before[b]['st'] = val
                    else: boat_before[b] = {'st': val, 'ex_time': 6.8}
        except: pass

        # Parse List
        rows = []
        try:
            for i, tb in enumerate(soup_list.select("tbody.is-fs12")):
                bn = i + 1
                if bn > 6: break
                
                # Racer ID
                racer_id = 9999
                try: 
                    txt = tb.select("td")[2].select_one("div").get_text()
                    racer_id = int(re.search(r'(\d{4})', txt).group(1))
                except: pass

                # Branch (Prefecture) & Weight
                branch = 'Unknown'
                weight = 52.0
                try:
                    txt = tb.select("td")[2].get_text(separator=' ')
                    # "4350 ç¯ å´ ä»å¿— åŸ¼ç‰ 52.0kg ..."
                    match = re.search(r'(\d{2}\.\d)kg', txt)
                    if match: weight = float(match.group(1))
                except: pass

                # Win Rates (National & Local)
                # Col 3: F0 L0 0.14 6.89 50.5 ...
                nat_win_rate = 0.0
                local_win_rate = 0.0
                try:
                    col3_txt = tb.select("td")[3].get_text(" ", strip=True)
                    # Use broad regex for any number
                    # Remove F/L to avoid parsing 0 from F0
                    clean_txt = re.sub(r'[FLK]\d+', '', col3_txt) 
                    nums = re.findall(r'(\d+(?:\.\d+)?)', clean_txt)
                    
                    if len(nums) >= 5:
                        # [AvgST, NatWin, Nat2, LocWin, Loc2]
                        nat_win_rate = float(nums[1])
                        local_win_rate = float(nums[3])
                    elif len(nums) >= 4:
                        # [NatWin, Nat2, LocWin, Loc2]
                        nat_win_rate = float(nums[0])
                        local_win_rate = float(nums[2])
                except: pass

                # Prior Results (Series Results)
                # Usually the last column or Col 8
                prior_results = ""
                try:
                    # Last column
                    prior_results = tb.select("td")[-1].get_text(" ", strip=True)
                except: pass

                # Rates
                # Column 6: Motor (No / Rate) e.g. "43 32.5%"
                # Column 7: Boat (No / Rate) e.g. "14 31.0%"
                tds = tb.select("td")
                
                motor = 30.0
                try:
                    txt = tds[6].get_text(" ", strip=True).replace('%', '')
                    parts = txt.split()
                    if len(parts) >= 2: motor = float(parts[1])
                    else: motor = float(parts[0])
                except: pass
                
                boat = 30.0
                try:
                    txt = tds[7].get_text(" ", strip=True).replace('%', '')
                    parts = txt.split()
                    if len(parts) >= 2: boat = float(parts[1])
                    else: boat = float(parts[0])
                except: pass
                
                row = {
                    'race_id': f"{date_str}_{venue_code}_{race_no}",
                    'boat_number': bn,
                    'racer_id': racer_id,
                    'motor_rate': motor,
                    'boat_rate': boat,
                    'exhibition_time': boat_before.get(bn, {}).get('ex_time', 6.8),
                    'exhibition_start_timing': boat_before.get(bn, {}).get('st', 0.20),
                    'pred_course': bn,
                    'wind_direction': weather['wind_direction'],
                    'wind_speed': weather['wind_speed'],
                    'wave_height': weather['wave_height'],
                    'prior_results': prior_results,
                    'branch': branch,
                    'weight': weight,
                    'nat_win_rate': nat_win_rate,
                    'local_win_rate': local_win_rate,
                    'makuri_count': 0, 'nige_count': 0
                }
                rows.append(row)
        except Exception as e:
            st.error(f"List Parse Error: {e}")
            return None
            
        return pd.DataFrame(rows)

# --- 2. Feature Engineer ---
class FeatureEngineer:
    @staticmethod
    def process_wind_data(df):
        # 1. Map Wind Direction (Text -> Angle)
        direction_map = {
            'åŒ—': 0, 'åŒ—æ±': 45, 'æ±': 90, 'å—æ±': 135,
            'å—': 180, 'å—è¥¿': 225, 'è¥¿': 270, 'åŒ—è¥¿': 315,
            'ç„¡é¢¨': 0, 'failed': 0, '': 0, 0: 0 # Handle int input
        }
        # In App, scraper returns int (1-16) or text?
        # Scraper returns int (1=North=0deg, 2=NE=45deg... 16=North=0)
        # 1=North, 2=NNE, 3=NE, 4=ENE, 5=East... 16=NNW?
        # BoatRace.jp logic: 1~16. 1=North(0), 5=East(90), 9=South(180), 13=West(270)
        # So map is: (val-1) * 22.5
        # Scraper already parses `is-windDirection` class to int?
        # Let's check scraper: `int(re.sub(r'\D', '', dir_cls))` -> 1..16
        # So we need 1..16 map.
        
        # Override map for 1..16 int input
        def wind_deg_from_int(x):
            if x < 1 or x > 16: return 0
            return (x - 1) * 22.5

        # Scraper returns int 1-16
        df['wind_angle_deg'] = df['wind_direction'].apply(wind_deg_from_int)

        # Venue Tailwind map (Heading of 1M - From which wind comes as tailwind)
        venue_tailwind_from = {
            'æ¡ç”Ÿ': 135, 'æˆ¸ç”°': 90, 'æ±Ÿæˆ¸å·': 180, 'å¹³å’Œå³¶': 180, 'å¤šæ‘©å·': 270,
            'æµœåæ¹–': 180, 'è’²éƒ¡': 270, 'å¸¸æ»‘': 270, 'æ´¥': 135, 'ä¸‰å›½': 180,
            'ã³ã‚ã“': 225, 'ä½ä¹‹æ±Ÿ': 270, 'å°¼å´': 90, 'é³´é–€': 135, 'ä¸¸äº€': 180,
            'å…å³¶': 225, 'å®®å³¶': 270, 'å¾³å±±': 135, 'ä¸‹é–¢': 270, 'è‹¥æ¾': 270,
            'èŠ¦å±‹': 135, 'ç¦å²¡': 0, 'å”æ´¥': 135, 'å¤§æ‘': 315
        }
        
        df['venue_tailwind_deg'] = df['venue_name'].map(venue_tailwind_from).fillna(0)
        
        # Vectors
        angle_diff_rad = np.radians(df['wind_angle_deg'] - df['venue_tailwind_deg'])
        df['wind_vector_long'] = df['wind_speed'] * np.cos(angle_diff_rad)
        df['wind_vector_lat'] = df['wind_speed'] * np.sin(angle_diff_rad)
        
        return df

    @staticmethod
    def process(df, venue_name):
        # Add missing venue_name column if not present (for mapping)
        df['venue_name'] = venue_name
        
        # Load Static Data
        try:
            r_course = pd.read_csv(os.path.join(DATA_DIR, 'static_racer_course.csv'))
            r_venue = pd.read_csv(os.path.join(DATA_DIR, 'static_racer_venue.csv'))
            v_course = pd.read_csv(os.path.join(DATA_DIR, 'static_venue_course.csv'))
            r_params = pd.read_csv(os.path.join(DATA_DIR, 'static_racer_params.csv'))
            
            # Ensure Types
            df['racer_id'] = df['racer_id'].astype(int)
            df['pred_course'] = df['pred_course'].astype(int)
            r_course['RacerID'] = r_course['RacerID'].astype(int)
            r_course['Course'] = r_course['Course'].astype(int)
            r_venue['RacerID'] = r_venue['RacerID'].astype(int)
            v_course['course_number'] = v_course['course_number'].astype(int)
            r_params['racer_id'] = r_params['racer_id'].astype(int)

            # --- Merges ---
            # 1. Racer Course Stats: [RacerID, Course] -> [course_run_count, course_quinella_rate...]
            # static_racer_course.csv cols: RacerID, Course, RacesRun, QuinellaRate, TrifectaRate, FirstPlaceRate, Nige, Makuri, Sashi
            df = df.merge(r_course, left_on=['racer_id', 'pred_course'], right_on=['RacerID', 'Course'], how='left')
            df.rename(columns={
                'RacesRun': 'course_run_count',
                'QuinellaRate': 'course_quinella_rate',
                'TrifectaRate': 'course_trifecta_rate',
                'FirstPlaceRate': 'course_1st_rate',
                'AvgStartTiming': 'course_avg_st', # Note: AvgStartTiming might be missing now? export didn't include it. 
                # Wait, export logic REMOVED AvgStartTiming in my update?
                # export_racer_course_stats selected: RacesRun, QuinellaRate, TrifectaRate, FirstPlaceRate, Nige, Makuri, Sashi.
                # It missed AvgStartTiming? 
                # I should assume course_avg_st is 0.17 if missing. Or scrape it?
                'Nige': 'nige_count_course', # conflict with global? No, app uses global nige_count?
                'Makuri': 'makuri_count_course',
                'Sashi': 'sashi_count_course'
            }, inplace=True)

            # 2. Racer Venue Stats
            if 'Venue' in r_venue.columns:
                df = df.merge(r_venue, left_on=['racer_id', 'venue_name'], right_on=['RacerID', 'Venue'], how='left')
            else:
                df = df.merge(r_venue, left_on=['racer_id'], right_on=['RacerID'], how='left')
            
            # Rename static WinRate
            if 'local_win_rate' in r_venue.columns:
                df.rename(columns={'local_win_rate': 'local_win_rate_static'}, inplace=True)
            elif 'WinRate' in df.columns: # fallback
                 df.rename(columns={'WinRate': 'local_win_rate_static'}, inplace=True)

            if 'local_win_rate' in df.columns:
                df['local_win_rate'] = df['local_win_rate'].replace(0.0, np.nan)
                df['local_win_rate'] = df['local_win_rate'].fillna(df['local_win_rate_static'])
            else:
                df['local_win_rate'] = df.get('local_win_rate_static', 0.0)
                
            df.drop(columns=['local_win_rate_static'], inplace=True, errors='ignore')

            # 3. Venue Course Stats
            df = df.merge(v_course, left_on=['venue_name', 'pred_course'], right_on=['venue_name', 'course_number'], how='left')
            df.rename(columns={
                'rate_1st': 'venue_course_1st_rate',
                'rate_2nd': 'venue_course_2nd_rate',
                'rate_3rd': 'venue_course_3rd_rate'
            }, inplace=True)

            # 4. Racer Params: [racer_id] -> [st_std_dev, nat_win_rate, nige_count, makuri_count, sashi_count...]
            df = df.merge(r_params, on='racer_id', how='left')
            # static_racer_params now has: st_std_dev, nat_win_rate, nige_count, makuri_count, sashi_count
            
            # Handling scraper vs static for nat_win_rate
            if 'nat_win_rate_y' in df.columns: # Merge resulted directly
                # If scraper gave nat_win_rate_x (0.0), use _y
                df['nat_win_rate'] = df['nat_win_rate_x'].replace(0.0, np.nan).fillna(df['nat_win_rate_y'])
                df.drop(columns=['nat_win_rate_x', 'nat_win_rate_y'], inplace=True)
            
        except Exception as e:
            # st.error(f"Static Data Error: {e}")
            pass
            
        except Exception as e:
            # st.error(f"Static Data Error: {e}")
            pass
        
        # Fill NaNs from merges
        df = df.fillna(0)
        
        # --- Feature Engineering (Sync with make_data_set.py) ---
        
        # Helper for Series Avg (Mock/Parse)
        def parse_prior(x):
            if isinstance(x, (int, float)): return x
            return 3.5 # Default
        df['series_avg_rank'] = df['prior_results'].apply(parse_prior)

        # Rates
        df['makuri_rate'] = df['makuri_count'] / df['course_run_count'].replace(0, 1)
        df['nige_rate'] = df['nige_count'] / df['course_run_count'].replace(0, 1)

        # ST Calculation (Group by race_id - but here usually 1 race)
        # Sort just in case
        df = df.sort_values('pred_course')
        
        df['inner_st'] = df['exhibition_start_timing'].shift(1).fillna(0)
        df['inner_st_gap'] = df['exhibition_start_timing'] - df['inner_st']
        df['outer_st'] = df['exhibition_start_timing'].shift(-1).fillna(0)
        
        avg_neighbor = (df['inner_st'] + df['outer_st']) / 2
        # If edge, handle? Shift returns NaN which we filled 0. That's fine.
        df['slit_formation'] = df['exhibition_start_timing'] - avg_neighbor

        # Anti-Nige
        c1_nige = df.loc[df['pred_course']==1, 'nige_rate']
        val = c1_nige.values[0] if len(c1_nige) > 0 else 0.5
        df['anti_nige_potential'] = df['makuri_rate'] * (1 - val)

        # Wall Strength (Inner Quinella)
        df['wall_strength'] = df['course_quinella_rate'].shift(1).fillna(0)

        # Follow Potential (Inner Makuri * Self Quinella)
        df['follow_potential'] = df['makuri_rate'].shift(1).fillna(0) * df['course_quinella_rate']

        # Tenji Z-Score
        mean_t = df['exhibition_time'].mean()
        std_t = df['exhibition_time'].std()
        if std_t == 0: std_t = 1
        df['tenji_z_score'] = (mean_t - df['exhibition_time']) / std_t

        # Linear Rank
        df['linear_rank'] = df['exhibition_time'].rank(method='min', ascending=True)
        df['is_linear_leader'] = (df['linear_rank'] == 1).astype(int)

        # Weight Diff (User Weight - Avg)
        # Note: 'weight' might come from params or scraper. 
        # If scraper didn't get it, use params. 
        if 'weight_x' in df.columns: df['weight'] = df['weight_x'] # excessive merge handling
        if 'weight' not in df.columns: df['weight'] = 52.0
        
        df['weight_diff'] = df['weight'] - df['weight'].mean()

        # High Wind Alert
        df['high_wind_alert'] = (df['wind_speed'] >= 5).astype(int)

        # Local Perf Diff
        if 'nat_win_rate' not in df.columns: df['nat_win_rate'] = 0.0 
        if 'local_win_rate' not in df.columns: df['local_win_rate'] = 0.0
        
        # Ensure Types
        df['nat_win_rate'] = pd.to_numeric(df['nat_win_rate'], errors='coerce').fillna(0.0)
        df['local_win_rate'] = pd.to_numeric(df['local_win_rate'], errors='coerce').fillna(0.0)

        df['local_perf_diff'] = df['local_win_rate'] - df['nat_win_rate']

        # Wind Vectors
        df = FeatureEngineer.process_wind_data(df)

        # Ensure ALL model features exist
        # Add 'race_date' if not present (Scraper usually puts it in race_id or we need to pass it)
        # But 'race_date' column needed as Feature?
        # Check error log: ['race_date', ...] missing.
        # So we MUST add 'race_date'.
        # Since we only have 1 date for the race, we can fill it.
        # But LGBM expects Date? Or Category?
        # Train: Category. App: Object -> Category.
        # So assign string.
        if 'race_date' not in df.columns:
            # Extract from race_id "20251210_07_12" or similar
            # Or passed from arg process(df, venue_name) -> maybe add date?
            # Hack: extract from race_id
            try:
                df['race_date'] = df['race_id'].astype(str).apply(lambda x: x.split('_')[0] if '_' in x else '20000101')
            except:
                df['race_date'] = '20000101'
        
        # Missing column safeguard
        needed = ['nat_win_rate', 'sashi_count', 'course_run_count', 'course_quinella_rate', 
                  'course_trifecta_rate', 'course_1st_rate', 'course_avg_st', 
                  'venue_course_1st_rate', 'venue_course_2nd_rate', 'venue_course_3rd_rate']
        for c in needed:
            if c not in df.columns: df[c] = 0.0

        # Type Conversion
        ignore_cols = ['race_id', 'boat_number', 'racer_id', 'rank', 'venue_name', 'wind_direction', 'prior_results', 'syn_win_rate', 'exhibition_time']
        for col in df.columns:
            if col in ignore_cols: continue
            if df[col].dtype == 'object':
                df[col] = df[col].astype('category')
                
        return df

# --- 3. Main App ---
st.title("ğŸš¤ BoatRace AI Strategy: 'Structure & Value'")
st.markdown("Returns-Focused AI Prediction System")

# Sidebar
today = datetime.date.today()
target_date = st.sidebar.date_input("Date", today)
venue_map = {
    1: 'æ¡ç”Ÿ', 2: 'æˆ¸ç”°', 3: 'æ±Ÿæˆ¸å·', 4: 'å¹³å’Œå³¶', 5: 'å¤šæ‘©å·',
    6: 'æµœåæ¹–', 7: 'è’²éƒ¡', 8: 'å¸¸æ»‘', 9: 'æ´¥', 10: 'ä¸‰å›½',
    11: 'ã³ã‚ã“', 12: 'ä½ä¹‹æ±Ÿ', 13: 'å°¼å´', 14: 'é³´é–€', 15: 'ä¸¸äº€',
    16: 'å…å³¶', 17: 'å®®å³¶', 18: 'å¾³å±±', 19: 'ä¸‹é–¢', 20: 'è‹¥æ¾',
    21: 'èŠ¦å±‹', 22: 'ç¦å²¡', 23: 'å”æ´¥', 24: 'å¤§æ‘'
}
venue_code = st.sidebar.selectbox("Venue", list(venue_map.keys()), format_func=lambda x: f"{x:02d}: {venue_map[x]}")
venue_name = venue_map[venue_code]
race_no = st.sidebar.selectbox("Race No", range(1, 13))

if st.button("Analyze Race", type="primary"):
    date_str = target_date.strftime('%Y%m%d')
    st.info(f"Fetching Data: {venue_name} {race_no}R ({date_str})")
    
    # 1. Scrape
    with st.spinner("Scraping..."):
        df_race = BoatRaceScraper.get_race_data(date_str, venue_code, race_no)
    
    if df_race is not None:
        st.subheader("Live Race Data")
        cols = ['boat_number', 'racer_id', 'branch', 'weight', 'motor_rate', 'exhibition_time', 'exhibition_start_timing', 'wind_speed']
        st.dataframe(df_race[cols])
        
        # 2. Features
        with st.spinner("Processing..."):
            df_feat = FeatureEngineer.process(df_race, venue_name)
            
        # 3. Predict
        if os.path.exists(MODEL_PATH):
            try:
                model = lgb.Booster(model_file=MODEL_PATH)
                
                # Align columns
                # Align columns
                model_feats = model.feature_name()
                
                # --- Display Input Data ---
                st.subheader("ğŸ“Š Model Input Features")
                st.dataframe(df_feat[model_feats])
                
                # Predict
                X_pred = df_feat[model_feats]
                preds = model.predict(X_pred)
                df_feat['score'] = preds
                
                # 4. Result
                rank_df = df_feat[['boat_number', 'score']].sort_values('score', ascending=False)
                rank_df['rank'] = range(1, len(rank_df) + 1)
                
                st.divider()
                st.subheader("ğŸ¤– AI Prediction Ranking")
                st.dataframe(rank_df.set_index('rank'))
                
                scores = dict(zip(rank_df['boat_number'], rank_df['score']))
                boats_sorted = rank_df['boat_number'].tolist()
                
                # Generate Top Trifecta Combinations
                import itertools
                combos = list(itertools.permutations(boats_sorted, 3))
                c_list = []
                for c in combos:
                    # Score metric: Product of individual scores
                    s = scores[c[0]] * scores[c[1]] * scores[c[2]]
                    c_list.append({'combo': f"{c[0]}-{c[1]}-{c[2]}", 'val': s, 'p1': c[0]})
                
                df_c = pd.DataFrame(c_list).sort_values('val', ascending=False)
                
                # Strategy 1: Honmei (Top 5 Overall)
                st.subheader("ğŸ¯ Main Strategy (Honmei)")
                # Use enumerate to get 1,2,3... rank instead of shuffled index
                for i, (_, row) in enumerate(df_c.head(5).iterrows()):
                    label = f"Rank {i+1}"
                    if i == 0:
                        label += " ğŸ”¥ (50å€ä»¥ä¸Šãªã‚‰å‹è² æ™‚)"
                        st.success(f"{label}: {row['combo']}")
                    else:
                        st.metric(label, row['combo'])
            except Exception as e:
                st.error(f"AI Model Error: {e}")
        else:
            st.warning("Model file (lgb_ranker.txt) not found.")
    else:
        st.error("Failed to load race data.")
