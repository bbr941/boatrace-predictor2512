import streamlit as st
import pandas as pd
import numpy as np
import lightgbm as lgb
import requests
from bs4 import BeautifulSoup
import datetime
import os

# Config
MODEL_PATH = 'lgb_ranker.txt'
DATA_DIR = 'app_data'

# --- 1. Scraper Functions ---
@st.cache_data(ttl=300)
def get_race_data(date_str, venue_code, race_no):
    jcd = f"{int(venue_code):02d}"
    
    # URLs
    url_before = f"https://www.boatrace.jp/owpc/pc/race/beforeinfo?rno={race_no}&jcd={jcd}&hd={date_str}"
    url_list = f"https://www.boatrace.jp/owpc/pc/race/racelist?rno={race_no}&jcd={jcd}&hd={date_str}"
    
    headers = {"User-Agent": "Mozilla/5.0"}

    try:
        resp_before = requests.get(url_before, headers=headers)
        resp_list = requests.get(url_list, headers=headers)
        resp_before.raise_for_status()
        resp_list.raise_for_status()
    except Exception as e:
        st.error(f"Network Error: {e}")
        return None

    # Parse Tables via Pandas
    try:
        dfs_before = pd.read_html(resp_before.content)
        dfs_list = pd.read_html(resp_list.content)
    except ValueError:
        st.warning("No tables found. Race might be cancelled or invalid.")
        return None
        
    # Heuristic to find correct tables
    # Before Info Table: Usually has columns like "å±•ç¤ºã‚¿ã‚¤ãƒ ", "ãƒãƒ«ãƒˆ"
    # Race List Table: Usually has columns like "å…¨å›½å‹ç‡", "ãƒ¢ãƒ¼ã‚¿ãƒ¼"
    
    df_before = None
    for d in dfs_before:
        if 'å±•ç¤ºã‚¿ã‚¤ãƒ ' in str(d.columns) or 'Exhibition' in str(d.columns):
            df_before = d
            break
    if df_before is None and len(dfs_before) >= 1:
         # Fallback to 2nd table if unnamed
         df_before = dfs_before[-1] # Often the bottom one

    df_list = None
    for d in dfs_list:
        if 'å…¨å›½' in str(d.columns) or 'å‹ç‡' in str(d.columns):
            df_list = d
            break
    if df_list is None and len(dfs_list) >= 1:
        df_list = dfs_list[0]

    if df_before is None or df_list is None:
         st.error("Could not identify race tables.")
         return None
         
    # Parse Wind (Soup)
    soup_before = BeautifulSoup(resp_before.content, 'html.parser')
    wind_direction = "ç„¡é¢¨"
    wind_speed = 0.0
    
    try:
        # Locate wind info
        # Structure varies, but often in a 'weather1_bodyUnit' div
        # <div class="weather1_bodyUnit"> ... <p class="is-direction16"> ... <span class="weather1_bodyUnitLabelData">5m</span>
        # direction16 class might map to direction.
        # Let's try text scraping if class is unstable.
        
        # Safe fallback: 0
        pass
    except:
        pass
        
    # Construct DataFrame
    rows = []
    
    # Map Venue Code to Name
    venue_map = {
        1: 'æ¡ç”Ÿ', 2: 'æˆ¸ç”°', 3: 'æ±Ÿæˆ¸å·', 4: 'å¹³å’Œå³¶', 5: 'å¤šæ‘©å·',
        6: 'æµœåæ¹–', 7: 'è’²éƒ¡', 8: 'å¸¸æ»‘', 9: 'æ´¥', 10: 'ä¸‰å›½',
        11: 'ã³ã‚ã“', 12: 'ä½ä¹‹æ±Ÿ', 13: 'å°¼å´', 14: 'é³´é–€', 15: 'ä¸¸äº€',
        16: 'å…å³¶', 17: 'å®®å³¶', 18: 'å¾³å±±', 19: 'ä¸‹é–¢', 20: 'è‹¥æ¾',
        21: 'èŠ¦å±‹', 22: 'ç¦å²¡', 23: 'å”æ´¥', 24: 'å¤§æ‘'
    }
    venue_name = venue_map.get(int(venue_code), 'Unknown')
    
    for i in range(6):
        # We assume tables are sorted by Boat 1-6
        # Need to verify if `df_before` and `df_list` have 6 rows corresponding to boats 1-6
        # Usually they do.
        
        if i >= len(df_list) or i >= len(df_before): break
        
        row = {}
        row['race_id'] = f"{date_str}_{venue_code}_{race_no}_{i}"
        row['boat_number'] = i + 1
        row['venue_name'] = venue_name
        
        # Scrape List Info
        # Need to be smart about column indices or names.
        # df_list.columns might be MultiIndex.
        # Flatten columns
        
        # --- Racer ID ---
        # Usually in a column with 'ç™»éŒ²ç•ªå·'
        # Let's try locating it.
        # For simplicity in this demo, I will use placeholder if parsing fails.
        row['racer_id'] = 4000 + i # Dummy
        
        # --- Rates ---
        row['nat_win_rate'] = 5.0 # Dummy
        row['motor_rate'] = 30.0
        row['boat_rate'] = 30.0
        
        # --- Before Info ---
        row['weight'] = 50.0
        row['exhibition_time'] = 6.8
        row['exhibition_start_timing'] = 0.15
        row['pred_course'] = i + 1
        
        # Wind
        row['wind_direction'] = wind_direction
        row['wind_speed'] = wind_speed
        row['wave_height'] = 0.0
        
        # Placeholder for Prior Results (Current Series)
        row['prior_results'] = "123" # Dummy
        
        rows.append(row)
        
    return pd.DataFrame(rows)

def process_data(df):
    # Load Lookups
    r_course = pd.read_csv(os.path.join(DATA_DIR, 'static_racer_course.csv'))
    r_venue = pd.read_csv(os.path.join(DATA_DIR, 'static_racer_venue.csv'))
    v_course = pd.read_csv(os.path.join(DATA_DIR, 'static_venue_course.csv'))
    r_params = pd.read_csv(os.path.join(DATA_DIR, 'static_racer_params.csv'))
    
    # Merge (Left Join on IDs)
    # racer_id int, venue_name, boat_number
    
    # 1. Racer Course Stats (Needs Course, which is 'pred_course')
    df['racer_id'] = df['racer_id'].astype(int)
    df['pred_course'] = df['pred_course'].astype(int)
    
    # Rename lookups to avoid collision if needed
    # r_course: RacerID, Course, QuinellaRate...
    df = pd.merge(df, r_course, 
                  left_on=['racer_id', 'pred_course'], 
                  right_on=['RacerID', 'Course'], 
                  how='left')
                  
    # 2. Racer Venue Stats
    df = pd.merge(df, r_venue, 
                  left_on=['racer_id', 'venue_name'],
                  right_on=['RacerID', 'Venue'],
                  how='left')
                  
    # 3. Venue Course Rates
    # v_course: venue_name, venue_code, course_number...
    # We have venue_name in df
    df = pd.merge(df, v_course,
                  left_on=['venue_name', 'pred_course'],
                  right_on=['venue_name', 'course_number'],
                  how='left')
                  
    # 4. Global Params (ST Dev)
    df = pd.merge(df, r_params, on='racer_id', how='left')
    
    # Fill NAs
    df = df.fillna(0)
    
    # --- Feature Engineering (Wind Vector) ---
    # Need `process_wind_data` logic
    direction_map = {
        'åŒ—': 0, 'åŒ—æ±': 45, 'æ±': 90, 'å—æ±': 135,
        'å—': 180, 'å—è¥¿': 225, 'è¥¿': 270, 'åŒ—è¥¿': 315,
        'ç„¡é¢¨': 0
    }
    venue_tailwind_from = {
         'æ¡ç”Ÿ': 135, 'æˆ¸ç”°': 90, 'æ±Ÿæˆ¸å·': 180, 'å¹³å’Œå³¶': 180, 'å¤šæ‘©å·': 270,
         'æµœåæ¹–': 180, 'è’²éƒ¡': 270, 'å¸¸æ»‘': 270, 'æ´¥': 135, 'ä¸‰å›½': 180,
         'ã³ã‚ã“': 225, 'ä½ä¹‹æ±Ÿ': 270, 'å°¼å´': 90, 'é³´é–€': 135, 'ä¸¸äº€': 180,
         'å…å³¶': 225, 'å®®å³¶': 270, 'å¾³å±±': 135, 'ä¸‹é–¢': 270, 'è‹¥æ¾': 270,
         'èŠ¦å±‹': 135, 'ç¦å²¡': 0, 'å”æ´¥': 135, 'å¤§æ‘': 315
    }
    
    df['wind_angle_deg'] = df['wind_direction'].map(direction_map).fillna(0)
    df['venue_tailwind_deg'] = df['venue_name'].map(venue_tailwind_from).fillna(0)
    
    angle_diff_rad = np.radians(df['wind_angle_deg'] - df['venue_tailwind_deg'])
    df['wind_vector_long'] = df['wind_speed'] * np.cos(angle_diff_rad)
    df['wind_vector_lat'] = df['wind_speed'] * np.sin(angle_diff_rad)
    
    # --- Other Features (Relative) ---
    # Simplified version of relative features
    # Inner ST Gap
    # Need to verify if 'exhibition_start_timing' is column
    
    # Return features found in model
    # Model expects specific feature names.
    # We should load model feature_name() or use consistent naming.
    # For now, just return df. The caller will filter columns.
    
    return df

# --- 3. UI ---
st.title("ğŸš¤ BoatRace Predictive AI")

st.sidebar.header("Settings")
target_date = st.sidebar.date_input("Date", datetime.date.today())
venue_code = st.sidebar.selectbox("Venue", range(1, 25), index=0) # 01-24
race_no = st.sidebar.selectbox("Race", range(1, 13))

if st.button("Predict"):
    date_str = target_date.strftime('%Y%m%d')
    st.write(f"Fetching data for JCD:{venue_code:02d} R:{race_no} Date:{date_str}...")
    
    # 1. Scrape
    df_raw = get_race_data(date_str, venue_code, race_no)
    
    if df_raw is not None:
        st.dataframe(df_raw)
        
        # 2. Process
        # df_test, features = process_data(df_raw)
        
        # 3. Predict
        # model = lgb.Booster(model_file=MODEL_PATH)
        # preds = model.predict(df_test[features])
        
        # 4. Display
        # st.bar_chart(preds)
    else:
        st.error("Failed to get race data.")

st.info("Note: This is a demo template. Scraper logic needs robust HTML parsing implementation.")
